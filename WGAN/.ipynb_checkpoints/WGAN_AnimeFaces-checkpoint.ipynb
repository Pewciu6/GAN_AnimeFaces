{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc5af381-1289-4d75-97c6-a6eba7e7c203",
   "metadata": {},
   "source": [
    "# Setup and Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1792c0-26f6-4b40-8f30-799e0ebf0d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.utils import save_image\n",
    "from torch_fidelity import calculate_metrics\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51363b9-6416-4bf3-8cba-28d0b52f4b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa09ba8-84b0-4936-ab6f-7f15ad03b7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "workers = 8\n",
    "\n",
    "dataset = dset.ImageFolder(root=\"data\",\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93880d68-bd6a-4625-bdc7-b19284198c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for batch_idx, (data, labels) in enumerate(dataloader):\n",
    "   # print(f\"Batch {batch_idx + 1}:\")\n",
    "   # print(f\"  - Data shape (images): {data.shape}\")\n",
    "   # print(f\"  - Labels shape: {labels.shape}\") \n",
    "\n",
    "   # if batch_idx == 2:\n",
    "   #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76417849-5d49-49be-a39d-66125d428769",
   "metadata": {},
   "source": [
    "# Model Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b1e5ce-a88e-409c-9a11-9d2d34c3b3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, color_channels, discriminator_features):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.dis = nn.Sequential(\n",
    "            \n",
    "            # Input: (input_channels) x 64 x 64\n",
    "            nn.Conv2d(color_channels, discriminator_features, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # State size: (discriminator_features) x 32 x 32\n",
    "            \n",
    "            nn.Conv2d(discriminator_features, discriminator_features * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(discriminator_features * 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # State size: (discriminator_features*2) x 16 x 16\n",
    "            \n",
    "            nn.Conv2d(discriminator_features * 2, discriminator_features * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(discriminator_features * 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # State size: (discriminator_features*4) x 8 x 8\n",
    "            \n",
    "            nn.Conv2d(discriminator_features * 4, discriminator_features * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(discriminator_features * 8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # State size: (discriminator_features*8) x 4 x 4\n",
    "            \n",
    "            nn.Conv2d(discriminator_features * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.dis(input).view(-1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1b4b3c-dd5d-4969-8c61-fdad6f1ff5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, generator_features, color_channels):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            # Input: (latent_dim, 1, 1)\n",
    "            nn.ConvTranspose2d(latent_dim, generator_features * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(generator_features * 8),\n",
    "            nn.ReLU(),\n",
    "            # State: (512, 4, 4)\n",
    "\n",
    "            nn.ConvTranspose2d(generator_features * 8, generator_features * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(generator_features * 4),\n",
    "            nn.ReLU(),\n",
    "            # State: (256, 8, 8)\n",
    "\n",
    "            nn.ConvTranspose2d(generator_features * 4, generator_features * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(generator_features * 2),\n",
    "            nn.ReLU(),\n",
    "            # State: (128, 16, 16)\n",
    "\n",
    "            nn.ConvTranspose2d(generator_features * 2, generator_features, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(generator_features),\n",
    "            nn.ReLU(),\n",
    "            # State: (64, 32, 32)\n",
    "\n",
    "            nn.ConvTranspose2d(generator_features, color_channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # Output: (3, 64, 64)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bae579-de5c-4f80-913e-8772e7518590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_fid_samples(generator, num_samples=2000, dir=\"fid_samples\"):\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_samples // batch_size + 1):\n",
    "            z = torch.randn(batch_size, 100, 1, 1).to(device)\n",
    "            fake_images = generator(z)\n",
    "            for j, img in enumerate(fake_images):\n",
    "                idx = i * batch_size + j\n",
    "                if idx >= num_samples:\n",
    "                    break\n",
    "                save_image(img, f\"{dir}/sample_{idx}.png\", normalize=True)\n",
    "    generator.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab85458-abdd-40c1-b7dc-be40b599a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f98cc0d-3909-46a7-8c99-b9853afb7f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(critic, real, fake, device):\n",
    "    batch_size = real.shape[0]\n",
    "    epsilon = torch.rand(batch_size, 1, 1, 1, device=device)\n",
    "    interpolated = epsilon * real + (1-epsilon) * fake\n",
    "    \n",
    "    critic_scores = critic(interpolated)\n",
    "    \n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=critic_scores,\n",
    "        inputs=interpolated,\n",
    "        grad_outputs=torch.ones_like(critic_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True\n",
    "    )[0]\n",
    "    \n",
    "    gradients = gradients.view(gradients.shape[0], -1)\n",
    "    penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0191defb-28a8-4b6b-a7c9-cb5c7af81e34",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bb50fb-878d-4a55-8015-4c7ef7750b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnet = Generator(latent_dim=100, generator_features=64, color_channels=3).to(device)\n",
    "dnet = Discriminator(color_channels=3, discriminator_features=64).to(device)\n",
    "\n",
    "gnet.apply(weights_init)\n",
    "dnet.apply(weights_init)\n",
    "\n",
    "g_optim = torch.optim.Adam(gnet.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
    "d_optim = torch.optim.Adam(dnet.parameters(), lr=4e-4, betas=(0.5, 0.999))\n",
    "\n",
    "g_scheduler = torch.optim.lr_scheduler.ExponentialLR(g_optim, gamma=0.99)\n",
    "d_scheduler = torch.optim.lr_scheduler.ExponentialLR(d_optim, gamma=0.99)\n",
    "\n",
    "lossFn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49823b92-37e1-4680-bad3-a4495873caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"samples\", exist_ok=True)\n",
    "os.makedirs(\"generated_fid_samples\", exist_ok=True)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "losses = np.zeros((epochs,2))\n",
    "decisions = np.zeros((epochs,2))\n",
    "\n",
    "fixed_noise = torch.randn(64, 100, 1, 1).to(device)\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    d_loss_epoch = 0\n",
    "    g_loss_epoch = 0\n",
    "    d_real_epoch = 0\n",
    "    d_fake_epoch = 0\n",
    "    \n",
    "    for i, (X,_) in enumerate(dataloader):\n",
    "\n",
    "        real_images = X.to(device)\n",
    "        batch_size = real_images.size(0)\n",
    "        fake_images = gnet(torch.randn(batch_size, 100, 1, 1).to(device))\n",
    "\n",
    "        real = torch.full((batch_size,), 0.9, device=device)\n",
    "        fake = torch.full((batch_size,), 0.1, device=device)\n",
    "\n",
    "        # ---- Disctriminator step ----\n",
    "\n",
    "        # True images\n",
    "        pred_real = dnet(real_images).view(-1)\n",
    "        d_loss_real = lossFn(real, pred_real)\n",
    "\n",
    "        # False images\n",
    "        pred_fake = dnet(fake_images).view(-1)\n",
    "        d_loss_fake = lossFn(fake, pred_fake)\n",
    "\n",
    "        # Combine the losses\n",
    "        d_loss_combined = d_loss_real + d_loss_fake\n",
    "\n",
    "        d_optim.zero_grad()\n",
    "        d_loss_combined.backward()\n",
    "        d_optim.step()\n",
    "\n",
    "\n",
    "        # ---- Generator step ----\n",
    "        fake_images = gnet( torch.randn(batch_size,100,1,1).to(device) )\n",
    "        pred_fake   = dnet(fake_images)\n",
    "      \n",
    "        # compute and collect loss and accuracy\n",
    "        g_loss = lossFn(pred_fake.squeeze(),real)\n",
    "         \n",
    "        g_optim.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optim.step()\n",
    "\n",
    "        d_loss_epoch += d_loss_combined.item()\n",
    "        g_loss_epoch += g_loss.item()\n",
    "        d_real_epoch += torch.mean((pred_real>.5).float()).item()\n",
    "        d_fake_epoch += torch.mean((pred_fake<.5).float()).item()\n",
    "\n",
    "    g_scheduler.step()\n",
    "    d_scheduler.step()\n",
    "\n",
    "    losses[epoch, 0] = d_loss_epoch/len(dataloader)\n",
    "    losses[epoch, 1] = g_loss_epoch/len(dataloader)\n",
    "    decisions[epoch, 0] = d_real_epoch/len(dataloader)\n",
    "    decisions[epoch, 1] = d_fake_epoch/len(dataloader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        fake = gnet(fixed_noise).detach().cpu()\n",
    "        save_image(fake, f'samples/epoch_{epoch+1}.png', nrow=8, normalize=True)\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        generate_and_save_fid_samples(gnet, num_samples=2000, dir=\"generated_fid_samples\")\n",
    "        \n",
    "        metrics_dict = calculate_metrics(\n",
    "            input1=\"data/data\",\n",
    "            input2=\"generated_fid_samples\",\n",
    "            cuda=True,\n",
    "            fid=True,\n",
    "            isc=False,\n",
    "            kid=False,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        fid = metrics_dict['frechet_inception_distance']\n",
    "        print(f\"Epoch {epoch}: FID={fid:.2f}, LR={g_optim.param_groups[0]['lr']:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf63a6af-de3b-4b81-bc16-2e51d577812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,ax = plt.subplots(1,3,figsize=(18,5))\n",
    "\n",
    "ax[0].plot(losses)\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_title('Model loss')\n",
    "ax[0].legend(['Discrimator','Generator'])\n",
    "\n",
    "ax[1].plot(losses[::5,0],losses[::5,1],'k.',alpha=.1)\n",
    "ax[1].set_xlabel('Discriminator loss')\n",
    "ax[1].set_ylabel('Generator loss')\n",
    "\n",
    "ax[2].plot(decisions)\n",
    "ax[2].set_xlabel('Epochs')\n",
    "ax[2].set_ylabel('Probablity (\"real\")')\n",
    "ax[2].set_title('Discriminator output')\n",
    "ax[2].legend(['Real','Fake'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b7f14a-403a-49dc-85d9-2e2860fba01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnet.eval()\n",
    "with torch.no_grad():\n",
    "    fake_data = gnet(torch.randn(12, 100, 1, 1).to(device)).cpu()\n",
    "    \n",
    "    fake_data = fake_data.permute(0, 2, 3, 1)  # Change from (N,C,H,W) to (N,H,W,C)\n",
    "    fake_data = (fake_data + 1) / 2  # Scale from [-1,1] to [0,1]\n",
    "\n",
    "    fig, axs = plt.subplots(3, 4, figsize=(8, 6))\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        ax.imshow(fake_data[i])\n",
    "        ax.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
